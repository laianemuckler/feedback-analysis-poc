"""
Pr√©-processamento de texto para an√°lise de feedbacks
"""
import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
import joblib
import os
from utils import clean_text, CONFIG

class FeedbackPreprocessor:
    """
    Classe para pr√©-processamento de feedbacks
    """
    
    def __init__(self):
        self.vectorizer = TfidfVectorizer(
            max_features=CONFIG['tfidf_max_features'],
            min_df=CONFIG['tfidf_min_df'], 
            max_df=CONFIG['tfidf_max_df'],
            ngram_range=(1, 2),  # Unigramas e bigramas
            lowercase=True,
            stop_words=None  # J√° removemos na limpeza
        )
        self.is_fitted = False
        
    def clean_texts(self, texts):
        """
        Limpa lista de textos
        """
        print("üßπ Limpando textos...")
        cleaned = []
        
        for i, text in enumerate(texts):
            cleaned_text = clean_text(text)
            cleaned.append(cleaned_text)
            
            if (i + 1) % 100 == 0:
                print(f"‚úÖ Limpeza: {i + 1}/{len(texts)} textos processados")
        
        return cleaned
    
    def fit_transform(self, texts):
        """
        Treina o vectorizador e transforma os textos
        """
        print("üî¢ Vectorizando textos com TF-IDF...")
        
        # Limpar textos
        clean_texts = self.clean_texts(texts)
        
        # Remover textos vazios
        valid_texts = [text for text in clean_texts if text.strip()]
        
        if len(valid_texts) == 0:
            raise ValueError("Nenhum texto v√°lido ap√≥s limpeza!")
        
        # Treinar e transformar
        tfidf_matrix = self.vectorizer.fit_transform(valid_texts)
        self.is_fitted = True
        
        print(f"‚úÖ Vectoriza√ß√£o completa!")
        print(f"üìä Matriz TF-IDF: {tfidf_matrix.shape[0]} documentos x {tfidf_matrix.shape[1]} features")
        print(f"üéØ Features mais importantes: {self.get_top_features(10)}")
        
        return tfidf_matrix, valid_texts
    
    def transform(self, texts):
        """
        Transforma novos textos (vectorizador j√° treinado)
        """
        if not self.is_fitted:
            raise ValueError("Vectorizador n√£o foi treinado! Use fit_transform primeiro.")
        
        clean_texts = self.clean_texts(texts)
        valid_texts = [text for text in clean_texts if text.strip()]
        
        return self.vectorizer.transform(valid_texts), valid_texts
    
    def get_feature_names(self):
        """
        Retorna nomes das features
        """
        if not self.is_fitted:
            return []
        return self.vectorizer.get_feature_names_out()
    
    def get_top_features(self, n=10):
        """
        Retorna top N features por import√¢ncia m√©dia
        """
        if not self.is_fitted:
            return []
        
        feature_names = self.get_feature_names()
        return list(feature_names[:n])
    
    def save_model(self, filepath='data/preprocessor_model.pkl'):
        """
        Salva o modelo treinado
        """
        if not self.is_fitted:
            print("‚ö†Ô∏è Modelo n√£o foi treinado ainda!")
            return False
        
        os.makedirs(os.path.dirname(filepath), exist_ok=True)
        joblib.dump(self.vectorizer, filepath)
        print(f"üíæ Modelo salvo em: {filepath}")
        return True
    
    def load_model(self, filepath='data/preprocessor_model.pkl'):
        """
        Carrega modelo pr√©-treinado
        """
        try:
            self.vectorizer = joblib.load(filepath)
            self.is_fitted = True
            print(f"üìÇ Modelo carregado de: {filepath}")
            return True
        except Exception as e:
            print(f"‚ùå Erro ao carregar modelo: {e}")
            return False

def preprocess_feedback_data(csv_path='data/feedbacks_sample.csv'):
    """
    Fun√ß√£o principal para processar dados de feedback
    """
    print("üöÄ Iniciando pr√©-processamento dos feedbacks...")
    
    # Carregar dados
    try:
        df = pd.read_csv(csv_path)
        print(f"üìä Dataset carregado: {len(df)} feedbacks")
    except Exception as e:
        print(f"‚ùå Erro ao carregar dataset: {e}")
        return None, None
    
    # Verificar coluna de texto
    if 'texto' not in df.columns:
        print("‚ùå Coluna 'texto' n√£o encontrada!")
        return None, None
    
    # Inicializar pr√©-processador
    preprocessor = FeedbackPreprocessor()
    
    # Processar textos
    try:
        tfidf_matrix, clean_texts = preprocessor.fit_transform(df['texto'].tolist())
        
        # Salvar modelo
        preprocessor.save_model()
        
        # Criar DataFrame processado
        processed_df = df.copy()
        processed_df['texto_limpo'] = clean_texts
        
        # Salvar dados processados
        output_path = 'data/feedbacks_processed.csv'
        processed_df.to_csv(output_path, index=False)
        print(f"üíæ Dados processados salvos em: {output_path}")
        
        return tfidf_matrix, processed_df, preprocessor
        
    except Exception as e:
        print(f"‚ùå Erro durante processamento: {e}")
        return None, None, None

def demo_preprocessing():
    """
    Demonstra√ß√£o do pr√©-processamento
    """
    print("üéØ DEMO: Pr√©-processamento de Texto")
    print("=" * 50)
    
    # Textos exemplo
    exemplos = [
        "O smartphone √© EXCELENTE!!! Bateria dura muito!",
        "Base ficou oleosa na minha pele, n√£o gostei :(",  
        "Camiseta chegou com tamanho errado, muito grande",
        "Adorei o perfume, cheiro maravilhoso!!!"
    ]
    
    print("üìù Textos originais:")
    for i, texto in enumerate(exemplos, 1):
        print(f"{i}. {texto}")
    
    print("\nüßπ Ap√≥s limpeza:")
    for i, texto in enumerate(exemplos, 1):
        limpo = clean_text(texto)
        print(f"{i}. {limpo}")
    
    print("\n" + "=" * 50)

def main():
    """
    Fun√ß√£o principal - executa pr√©-processamento completo
    """
    # Demo primeiro
    demo_preprocessing()
    
    # Verificar se dataset existe
    if not os.path.exists('data/feedbacks_sample.csv'):
        print("‚ùå Dataset n√£o encontrado! Execute primeiro: python src/data_generator.py")
        return
    
    # Processar dados completos
    results = preprocess_feedback_data()
    
    if results[0] is not None:
        tfidf_matrix, processed_df, preprocessor = results
        print(f"\nüéâ Pr√©-processamento conclu√≠do com sucesso!")
        print(f"üìä Matriz TF-IDF: {tfidf_matrix.shape}")
        print(f"üéØ Pronto para clustering (Fase 3)!")
    else:
        print("\n‚ùå Falha no pr√©-processamento!")

if __name__ == "__main__":
    main()